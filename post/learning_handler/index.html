<html>
  <head>
    <meta charset="utf-8" />
<meta name="description" content="" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Handler学习 | Gridea</title>
<link rel="shortcut icon" href="http://xuwanjin.me//favicon.ico?v=1568639004354">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="http://xuwanjin.me//styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>



  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="http://xuwanjin.me/">
  <img class="avatar" src="http://xuwanjin.me//images/avatar.png?v=1568639004354" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>


        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Handler学习
            </h2>
            <div class="post-info">
              <time class="post-time">
                · 2019-09-15 ·
              </time>
              
                <a href="http://xuwanjin.me//tag/VS_FXwZ4Z" class="post-tag">
                  # Handler
                </a>
              
            </div>
            
              <div class="post-feature-image" style="background-image: url('http://xuwanjin.me//post-images/learning_handler.png')">
              </div>
            
            <div class="post-content">
              <h1 id="handler学习">Handler学习</h1>
<p>Message 分类<br>
同步消息<br>
异步消息<br>
延时消息<br>
非延时消息<br>
是否使用中<br>
Handler 作用是用来实现不同的线程间的通信. 主要是处理消息和发送消息<br>
Message 传递的消息, 以此为载体, 可以放入 bundle,<br>
Looper 用来获取消息的, 然后派发消息<br>
在消息的处理的线程里, 我们需要 new Handler , 并且重写 Handler 的 handleMessage 方法, 或者使用 Handler.Callback<br>
在消息的发送的线程里, 我们需要使用 handler 的 sendMessage 方法, 发送消息, 或者 post 一个 Runnable</p>
<h2 id="handler-demo">Handler Demo</h2>
<pre><code class="language-java">public class MainActivity extends AppCompatActivity {
    Handler handler;
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        // 线程 A 和线程 B 通信, 通过 Handler
        // 处理消息的线程, 需要接受消息线程, 
        new Thread(new Runnable() {
            @Override
            public void run() {
            // 使用 Handler 之前必须调用 Looper.prepare(), 
            // Android app 的主线程会在 ActivityThread 里调用
            // Looper.prepareMainLooper();
                Looper.prepare();
                handler = new Handler(Looper.myLooper(), new Handler.Callback() {
                 // 处理消息的
                    @Override
                    public boolean handleMessage(@NonNull Message message) {
                        Log.d(&quot;Matthew&quot;, &quot;receiver Message: callback&quot;);
                        // 如果这里返回了 true, dispatch 的时候, 
                        // Handler 类的 handleMessage 方法将不会被调用
                        return false; 
                    }
                }){
                // 处理消息的
                    @Override
                    public void handleMessage(@NonNull Message msg) {
                        super.handleMessage(msg);
                        if (msg.what == 123){
                            Log.d(&quot;Matthew&quot;, &quot;receiver Message: handler &quot;);
                        }
                    }
                };
                // 开始 Loop 循环, 开始循环的获取消息
                Looper.loop();
            }
        }).start();
        // Thread B 发送消息的线程
        new Thread(new Runnable() {
            @Override
            public void run() {
                do {
                    Log.d(&quot;Mathew&quot;, &quot;send Message&quot;);
                    try {
                        Thread.sleep(200);
                    } catch (InterruptedException e) {

                    }
                    handler.sendEmptyMessage(123);
                }while (true);
            }
        }).start();
    }
}
</code></pre>
<p>Handler 的作用</p>
<h2 id="相关流程">相关流程</h2>
<p>@(aosp/Android)</p>
<h3 id="prepare流程">prepare()流程</h3>
<pre><code class="language-java">// frameworks/base/core/java/android/os/Looper.java
public static void prepare() {
    prepare(true);
}
// quitAllowed 将被传递给 MessageQueue 的实例对象, 表示消息消息队列是否可以被 quit
private static void prepare(boolean quitAllowed) {
    if (sThreadLocal.get() != null) {
        throw new RuntimeException(&quot;Only one Looper may be created per thread&quot;);
    }
    // 将 Looper 的对象放入到 sThreadLocal 进行管理
    sThreadLocal.set(new Looper(quitAllowed));
}
</code></pre>
<pre><code class="language-java">// frameworks/base/core/java/android/os/Looper.java
private Looper(boolean quitAllowed) {
    mQueue = new MessageQueue(quitAllowed);
    // mThread 赋值当前的线程
    mThread = Thread.currentThread();
}
</code></pre>
<pre><code class="language-java">// frameworks/base/core/java/android/os/MessageQueue.java
// quitAllowed 将被传递给 MessageQueue 的实例对象, 表示消息消息队列是否可以被 quit
MessageQueue(boolean quitAllowed) {
   mQuitAllowed = quitAllowed;
   // native 初始化过程, 返回是什么? 地址?
   // 返回的是 nativeMessageQueue 对象经过reinterpret_cast转换过的对象
   mPtr = nativeInit();
}
</code></pre>
<pre><code class="language-java">// frameworks/base/core/java/android/os/MessageQueue.java
private native static long nativeInit();

</code></pre>
<pre><code class="language-java">// frameworks/base/core/jni/android_os_MessageQueue.cpp
static jlong android_os_MessageQueue_nativeInit(JNIEnv* env, jclass clazz) {
// 新建一个 NativeMessageQueue 对象.
    NativeMessageQueue* nativeMessageQueue = new NativeMessageQueue();
    if (!nativeMessageQueue) {
        jniThrowRuntimeException(env, &quot;Unable to allocate native queue&quot;);
        return 0;
    }

    nativeMessageQueue-&gt;incStrong(env);
    // reinterpret_cast 产生一个新的值, 这个新的值与nativeMessageQueue 有着相同的比特位 ???
    return reinterpret_cast&lt;jlong&gt;(nativeMessageQueue);
}
</code></pre>
<pre><code class="language-cpp">// frameworks/base/core/jni/android_os_MessageQueue.cpp
NativeMessageQueue::NativeMessageQueue() :
        mPollEnv(NULL), mPollObj(NULL), mExceptionObj(NULL) {
    // 获取一个 Looper 实例,通过gTLSKey 获取的 Looper 实例, 或者是新创建的
    mLooper = Looper::getForThread();
    if (mLooper == NULL) {
        mLooper = new Looper(false);
        // 新创建的 looper 对象放入到键值对里
        Looper::setForThread(mLooper);
    }
}
</code></pre>
<pre><code class="language-cpp">// frameworks/base/native/android/looper.cpp
sp&lt;Looper&gt; Looper::getForThread() {
    int result = pthread_once(&amp; gTLSOnce, initTLSKey);
    LOG_ALWAYS_FATAL_IF(result != 0, &quot;pthread_once failed&quot;);
// pthread_getpecific 和 pthread_setspecific　
// pthread_getpecific 将与 key 相关的数据读出来, 返回的数据类型是 void, 因此可以指向任何类型的数据
//https://linux.die.net/man/3/pthread_setspecific 具体见这个
// pthread_getspecific 会获取在这个线程下 gTLSKey 这个key通过 pthread_setspecific 设置的值, 
// 不同的线程这个 key 对应的 value 可能不一样
    return (Looper*)pthread_getspecific(gTLSKey);
}
</code></pre>
<pre><code class="language-cpp">// frameworks/base/native/android/looper.cpp
Looper::Looper(bool allowNonCallbacks) :
        mAllowNonCallbacks(allowNonCallbacks), mSendingMessage(false),
        mPolling(false), mEpollFd(-1), mEpollRebuildRequired(false),
        mNextRequestSeq(0), mResponseIndex(0), mNextMessageUptime(LLONG_MAX) {
        // 这里创建一个文件描述符 mWakeEventFd, 以后会监听这个文件描述符
    mWakeEventFd = eventfd(0, EFD_NONBLOCK | EFD_CLOEXEC);
    LOG_ALWAYS_FATAL_IF(mWakeEventFd &lt; 0, &quot;Could not make wake event fd: %s&quot;,
                        strerror(errno));

    AutoMutex _l(mLock);
    rebuildEpollLocked();
}
</code></pre>
<pre><code class="language-cpp">// system/core/libutils/Looper.cpp
void Looper::setForThread(const sp&lt;Looper&gt;&amp; looper) {
    sp&lt;Looper&gt; old = getForThread(); // also has side-effect of initializing TLS

    if (looper != NULL) {
        looper-&gt;incStrong((void*)threadDestructor);
    }
	// pthread_getpecific和pthread_setspecific 
	//https://linux.die.net/man/3/pthread_setspecific 具体见这个
    pthread_setspecific(gTLSKey, looper.get());

    if (old != NULL) {
        old-&gt;decStrong((void*)threadDestructor);
    }
}
</code></pre>
<pre><code class="language-cpp">// system/core/libutils/Looper.cpp
void Looper::rebuildEpollLocked() {
    // Close old epoll instance if we have one.
    if (mEpollFd &gt;= 0) {
#if DEBUG_CALLBACKS
        ALOGD(&quot;%p ~ rebuildEpollLocked - rebuilding epoll set&quot;, this);
#endif
        close(mEpollFd);
    }
    
    // Allocate the new epoll instance and register the wake pipe.
    // 创建一个 epoll 的文件描述符
    mEpollFd = epoll_create(EPOLL_SIZE_HINT);
    LOG_ALWAYS_FATAL_IF(mEpollFd &lt; 0, &quot;Could not create epoll instance: %s&quot;, strerror(errno));

    struct epoll_event eventItem;
    memset(&amp; eventItem, 0, sizeof(epoll_event)); // zero out unused members of data field union
    eventItem.events = EPOLLIN;
    eventItem.data.fd = mWakeEventFd;
    // 将被监听的描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改
    // 这里我们监听 mWakeEventFd 描述符
    int result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeEventFd, &amp; eventItem);
    LOG_ALWAYS_FATAL_IF(result != 0, &quot;Could not add wake event fd to epoll instance: %s&quot;,
                        strerror(errno));
    //mRequests ===&gt; Locked list of file descriptor monitoring requests. 
    // 不太明白是这里为什么这么做
    for (size_t i = 0; i &lt; mRequests.size(); i++) {
        const Request&amp; request = mRequests.valueAt(i);
        struct epoll_event eventItem;
        request.initEventItem(&amp;eventItem);

        int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, request.fd, &amp; eventItem);
        if (epollResult &lt; 0) {
            ALOGE(&quot;Error adding epoll events for fd %d while rebuilding epoll set: %s&quot;,
                  request.fd, strerror(errno));
        }
    }
}

</code></pre>
<pre><code class="language-cpp">int pthread_once(pthread_once_t* once_control, void (*init_routine)(void)) {
  static_assert(sizeof(atomic_int) == sizeof(pthread_once_t),
                &quot;pthread_once_t should actually be atomic_int in implementation.&quot;);

  // We prefer casting to atomic_int instead of declaring pthread_once_t to be atomic_int directly.
  // Because using the second method pollutes pthread.h, and causes an error when compiling libcxx.
  atomic_int* once_control_ptr = reinterpret_cast&lt;atomic_int*&gt;(once_control);

  // First check if the once is already initialized. This will be the common
  // case and we want to make this as fast as possible. Note that this still
  // requires a load_acquire operation here to ensure that all the
  // stores performed by the initialization function are observable on
  // this CPU after we exit.
  int old_value = atomic_load_explicit(once_control_ptr, memory_order_acquire);

  while (true) {
    if (__predict_true(old_value == ONCE_INITIALIZATION_COMPLETE)) {
      return 0;
    }

    // Try to atomically set the initialization underway flag. This requires a compare exchange
    // in a loop, and we may need to exit prematurely if the initialization is complete.
    if (!atomic_compare_exchange_weak_explicit(once_control_ptr, &amp;old_value,
                                               ONCE_INITIALIZATION_UNDERWAY,
                                               memory_order_acquire, memory_order_acquire)) {
      continue;
    }

    if (old_value == ONCE_INITIALIZATION_NOT_YET_STARTED) {
      // We got here first, we can handle the initialization.
      (*init_routine)();

      // Do a store_release indicating that initialization is complete.
      atomic_store_explicit(once_control_ptr, ONCE_INITIALIZATION_COMPLETE, memory_order_release);

      // Wake up any waiters, if any.
      __futex_wake_ex(once_control_ptr, 0, INT_MAX);
      return 0;
    }

    // The initialization is underway, wait for its finish.
    __futex_wait_ex(once_control_ptr, 0, old_value, false, nullptr);
    old_value = atomic_load_explicit(once_control_ptr, memory_order_acquire);
  }
}
</code></pre>
<h3 id="sendmessage-流程">sendMessage 流程</h3>
<h4 id="sendmessage">sendMessage</h4>
<pre><code class="language-java">// frameworks/base/core/java/android/os/Handler.java
public final boolean sendMessage(Message msg)
{
	// delay 的时间为零
    return sendMessageDelayed(msg, 0);
}
</code></pre>
<h4 id="sendmessagedelayed">sendMessageDelayed</h4>
<pre><code class="language-java">// frameworks/base/core/java/android/os/Handler.java
public final boolean sendMessageDelayed(Message msg, long delayMillis)
{
    if (delayMillis &lt; 0) {
        delayMillis = 0;
    }
    // 添加系统时间, 这个时间将成为 when 字段的值
    return sendMessageAtTime(msg, SystemClock.uptimeMillis() + delayMillis);
}
</code></pre>
<h4 id="sendmessageattime">sendMessageAtTime</h4>
<pre><code class="language-java">// frameworks/base/core/java/android/os/Handler.java
public boolean sendMessageAtTime(Message msg, long uptimeMillis) {
    MessageQueue queue = mQueue;
    if (queue == null) {
        RuntimeException e = new RuntimeException(
                this + &quot; sendMessageAtTime() called with no mQueue&quot;);
        Log.w(&quot;Looper&quot;, e.getMessage(), e);
        return false;
    }
    return enqueueMessage(queue, msg, uptimeMillis);
}
</code></pre>
<h4 id="enqueuemessage">enqueueMessage</h4>
<pre><code class="language-java">// frameworks/base/core/java/android/os/Handler.java
private boolean enqueueMessage(MessageQueue queue, Message msg, long uptimeMillis) {
    msg.target = this;
    if (mAsynchronous) {
        msg.setAsynchronous(true);
    }
    return queue.enqueueMessage(msg, uptimeMillis);
}

</code></pre>
<h4 id="enqueuemessage-2">enqueueMessage</h4>
<pre><code class="language-java">// frameworks/base/core/java/android/os/MessageQueue.java
boolean enqueueMessage(Message msg, long when) {
    if (msg.target == null) {
        throw new IllegalArgumentException(&quot;Message must have a target.&quot;);
    }
    if (msg.isInUse()) {
        throw new IllegalStateException(msg + &quot; This message is already in use.&quot;);
    }

    synchronized (this) {
        if (mQuitting) {
            IllegalStateException e = new IllegalStateException(
                    msg.target + &quot; sending message to a Handler on a dead thread&quot;);
            Log.w(TAG, e.getMessage(), e);
            msg.recycle();
            return false;
        }

        msg.markInUse();
        msg.when = when;
        Message p = mMessages;
        boolean needWake;
        if (p == null || when == 0 || when &lt; p.when) {
            // New head, wake up the event queue if blocked.
            msg.next = p;
            mMessages = msg;
            needWake = mBlocked;
        } else {
            // Inserted within the middle of the queue.  Usually we don't have to wake
            // up the event queue unless there is a barrier at the head of the queue
            // and the message is the earliest asynchronous message in the queue.
            needWake = mBlocked &amp;&amp; p.target == null &amp;&amp; msg.isAsynchronous();
            Message prev;
            for (;;) {
                prev = p;
                p = p.next;
                if (p == null || when &lt; p.when) {
                    break;
                }
                if (needWake &amp;&amp; p.isAsynchronous()) {
                    needWake = false;
                }
            }
            msg.next = p; // invariant: p == prev.next
            prev.next = msg;
        }

        // We can assume mPtr != 0 because mQuitting is false.
        if (needWake) {
            nativeWake(mPtr);
        }
    }
    return true;
}
</code></pre>
<h4 id="nativewake">nativeWake</h4>
<pre><code class="language-java">// frameworks/base/core/java/android/os/MessageQueue.java
private native static void nativeWake(long ptr);
</code></pre>
<h4 id="android_os_messagequeue_nativewake">android_os_MessageQueue_nativeWake</h4>
<pre><code class="language-cpp">// frameworks/base/core/jni/android_os_MessageQueue.cpp
static void android_os_MessageQueue_nativeWake(JNIEnv* env, jclass clazz, jlong ptr) {
    NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr);
    nativeMessageQueue-&gt;wake();
}
</code></pre>
<h4 id="nativemessagequeue-wake">NativeMessageQueue-&gt;wake</h4>
<pre><code class="language-cpp">// frameworks/base/core/jni/android_os_MessageQueue.cpp
void NativeMessageQueue::wake() {
    mLooper-&gt;wake();
}	
</code></pre>
<h4 id="looper-wake">Looper-&gt;wake</h4>
<pre><code class="language-cpp">// system/core/libutils/Looper.cpp
void Looper::wake() {
#if DEBUG_POLL_AND_WAKE
    ALOGD(&quot;%p ~ wake&quot;, this);
#endif

    uint64_t inc = 1;
    // 最重要的工作是写入 mWakeEventFd 这个文件描述符, 之前在 new Looper 的时候已经监听了这个值
    ssize_t nWrite = TEMP_FAILURE_RETRY(write(mWakeEventFd, &amp;inc, sizeof(uint64_t)));
    if (nWrite != sizeof(uint64_t)) {
        if (errno != EAGAIN) {
            LOG_ALWAYS_FATAL(&quot;Could not write wake signal to fd %d: %s&quot;,
                    mWakeEventFd, strerror(errno));
        }
    }
}
</code></pre>
<h4 id="pollall">pollAll</h4>
<pre><code class="language-cpp">int Looper::pollAll(int timeoutMillis, int* outFd, int* outEvents, void** outData) {
    if (timeoutMillis &lt;= 0) {
        int result;
        do {
            result = pollOnce(timeoutMillis, outFd, outEvents, outData);
        } while (result == POLL_CALLBACK);
        return result;
    } else {
        nsecs_t endTime = systemTime(SYSTEM_TIME_MONOTONIC)
                + milliseconds_to_nanoseconds(timeoutMillis);

        for (;;) {
            int result = pollOnce(timeoutMillis, outFd, outEvents, outData);
            if (result != POLL_CALLBACK) {
                return result;
            }

            nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC);
            timeoutMillis = toMillisecondTimeoutDelay(now, endTime);
            if (timeoutMillis == 0) {
                return POLL_TIMEOUT;
            }
        }
    }
}

</code></pre>
<pre><code class="language-cpp">int Looper::pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) {
    int result = 0;
    for (;;) {
        while (mResponseIndex &lt; mResponses.size()) {
            const Response&amp; response = mResponses.itemAt(mResponseIndex++);
            int ident = response.request.ident;
            if (ident &gt;= 0) {
                int fd = response.request.fd;
                int events = response.events;
                void* data = response.request.data;
#if DEBUG_POLL_AND_WAKE
                ALOGD(&quot;%p ~ pollOnce - returning signalled identifier %d: &quot;
                        &quot;fd=%d, events=0x%x, data=%p&quot;,
                        this, ident, fd, events, data);
#endif
                if (outFd != NULL) *outFd = fd;
                if (outEvents != NULL) *outEvents = events;
                if (outData != NULL) *outData = data;
                return ident;
            }
        }

        if (result != 0) {
#if DEBUG_POLL_AND_WAKE
            ALOGD(&quot;%p ~ pollOnce - returning result %d&quot;, this, result);
#endif
            if (outFd != NULL) *outFd = 0;
            if (outEvents != NULL) *outEvents = 0;
            if (outData != NULL) *outData = NULL;
            return result;
        }

        result = pollInner(timeoutMillis);
    }
}

</code></pre>
<h4 id="pollinner">pollInner</h4>
<pre><code class="language-cpp">int Looper::pollInner(int timeoutMillis) {
#if DEBUG_POLL_AND_WAKE
    ALOGD(&quot;%p ~ pollOnce - waiting: timeoutMillis=%d&quot;, this, timeoutMillis);
#endif

    // Adjust the timeout based on when the next message is due.
    if (timeoutMillis != 0 &amp;&amp; mNextMessageUptime != LLONG_MAX) {
        nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC);
        int messageTimeoutMillis = toMillisecondTimeoutDelay(now, mNextMessageUptime);
        if (messageTimeoutMillis &gt;= 0
                &amp;&amp; (timeoutMillis &lt; 0 || messageTimeoutMillis &lt; timeoutMillis)) {
            timeoutMillis = messageTimeoutMillis;
        }
#if DEBUG_POLL_AND_WAKE
        ALOGD(&quot;%p ~ pollOnce - next message in %&quot; PRId64 &quot;ns, adjusted timeout: timeoutMillis=%d&quot;,
                this, mNextMessageUptime - now, timeoutMillis);
#endif
    }

    // Poll.
    int result = POLL_WAKE;
    mResponses.clear();
    mResponseIndex = 0;

    // We are about to idle.
    mPolling = true;

    struct epoll_event eventItems[EPOLL_MAX_EVENTS];
    int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_EVENTS, timeoutMillis);

    // No longer idling.
    mPolling = false;

    // Acquire lock.
    mLock.lock();

    // Rebuild epoll set if needed.
    if (mEpollRebuildRequired) {
        mEpollRebuildRequired = false;
        rebuildEpollLocked();
        goto Done;
    }

    // Check for poll error.
    if (eventCount &lt; 0) {
        if (errno == EINTR) {
            goto Done;
        }
        ALOGW(&quot;Poll failed with an unexpected error: %s&quot;, strerror(errno));
        result = POLL_ERROR;
        goto Done;
    }

    // Check for poll timeout.
    if (eventCount == 0) {
#if DEBUG_POLL_AND_WAKE
        ALOGD(&quot;%p ~ pollOnce - timeout&quot;, this);
#endif
        result = POLL_TIMEOUT;
        goto Done;
    }

    // Handle all events.
#if DEBUG_POLL_AND_WAKE
    ALOGD(&quot;%p ~ pollOnce - handling events from %d fds&quot;, this, eventCount);
#endif

    for (int i = 0; i &lt; eventCount; i++) {
        int fd = eventItems[i].data.fd;
        uint32_t epollEvents = eventItems[i].events;
        if (fd == mWakeEventFd) {
            if (epollEvents &amp; EPOLLIN) {
                awoken();
            } else {
                ALOGW(&quot;Ignoring unexpected epoll events 0x%x on wake event fd.&quot;, epollEvents);
            }
        } else {
            ssize_t requestIndex = mRequests.indexOfKey(fd);
            if (requestIndex &gt;= 0) {
                int events = 0;
                if (epollEvents &amp; EPOLLIN) events |= EVENT_INPUT;
                if (epollEvents &amp; EPOLLOUT) events |= EVENT_OUTPUT;
                if (epollEvents &amp; EPOLLERR) events |= EVENT_ERROR;
                if (epollEvents &amp; EPOLLHUP) events |= EVENT_HANGUP;
                pushResponse(events, mRequests.valueAt(requestIndex));
            } else {
                ALOGW(&quot;Ignoring unexpected epoll events 0x%x on fd %d that is &quot;
                        &quot;no longer registered.&quot;, epollEvents, fd);
            }
        }
    }
Done: ;

    // Invoke pending message callbacks.
    mNextMessageUptime = LLONG_MAX;
    while (mMessageEnvelopes.size() != 0) {
        nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC);
        const MessageEnvelope&amp; messageEnvelope = mMessageEnvelopes.itemAt(0);
        if (messageEnvelope.uptime &lt;= now) {
            // Remove the envelope from the list.
            // We keep a strong reference to the handler until the call to handleMessage
            // finishes.  Then we drop it so that the handler can be deleted *before*
            // we reacquire our lock.
            { // obtain handler
                sp&lt;MessageHandler&gt; handler = messageEnvelope.handler;
                Message message = messageEnvelope.message;
                mMessageEnvelopes.removeAt(0);
                mSendingMessage = true;
                mLock.unlock();

#if DEBUG_POLL_AND_WAKE || DEBUG_CALLBACKS
                ALOGD(&quot;%p ~ pollOnce - sending message: handler=%p, what=%d&quot;,
                        this, handler.get(), message.what);
#endif
                handler-&gt;handleMessage(message);
            } // release handler

            mLock.lock();
            mSendingMessage = false;
            result = POLL_CALLBACK;
        } else {
            // The last message left at the head of the queue determines the next wakeup time.
            mNextMessageUptime = messageEnvelope.uptime;
            break;
        }
    }

    // Release lock.
    mLock.unlock();

    // Invoke all response callbacks.
    for (size_t i = 0; i &lt; mResponses.size(); i++) {
        Response&amp; response = mResponses.editItemAt(i);
        if (response.request.ident == POLL_CALLBACK) {
            int fd = response.request.fd;
            int events = response.events;
            void* data = response.request.data;
#if DEBUG_POLL_AND_WAKE || DEBUG_CALLBACKS
            ALOGD(&quot;%p ~ pollOnce - invoking fd event callback %p: fd=%d, events=0x%x, data=%p&quot;,
                    this, response.request.callback.get(), fd, events, data);
#endif
            // Invoke the callback.  Note that the file descriptor may be closed by
            // the callback (and potentially even reused) before the function returns so
            // we need to be a little careful when removing the file descriptor afterwards.
            int callbackResult = response.request.callback-&gt;handleEvent(fd, events, data);
            if (callbackResult == 0) {
                removeFd(fd, response.request.seq);
            }

            // Clear the callback reference in the response structure promptly because we
            // will not clear the response vector itself until the next poll.
            response.request.callback.clear();
            result = POLL_CALLBACK;
        }
    }
    return result;
}

</code></pre>
<h4 id="awoken">awoken</h4>
<pre><code class="language-cpp">void Looper::awoken() {
#if DEBUG_POLL_AND_WAKE
    ALOGD(&quot;%p ~ awoken&quot;, this);
#endif

    uint64_t counter;
    TEMP_FAILURE_RETRY(read(mWakeEventFd, &amp;counter, sizeof(uint64_t)));
}

</code></pre>
<h3 id="loop-流程">loop 流程</h3>
<h4 id="loop-loop">Loop-&gt;loop</h4>
<pre><code class="language-java">/**
    * Run the message queue in this thread. Be sure to call
    * {@link #quit()} to end the loop.
    */
// frameworks/base/core/java/android/os/Looper.java
public static void loop() {
    // 从sThreadLocal取出一个　Looper 对象
    final Looper me = myLooper();
    if (me == null) {
        throw new RuntimeException(&quot;No Looper; Looper.prepare() wasn't called on this thread.&quot;);
    }
    // 获取　Looper 的 mQueue 对象
    final MessageQueue queue = me.mQueue;

    // Make sure the identity of this thread is that of the local process,
    // and keep track of what that identity token actually is.
    Binder.clearCallingIdentity();
    final long ident = Binder.clearCallingIdentity();

    // Allow overriding a threshold with a system prop. e.g.
    // adb shell 'setprop log.looper.1000.main.slow 1 &amp;&amp; stop &amp;&amp; start'
    final int thresholdOverride =
            SystemProperties.getInt(&quot;log.looper.&quot;
                    + Process.myUid() + &quot;.&quot;
                    + Thread.currentThread().getName()
                    + &quot;.slow&quot;, 0);

    boolean slowDeliveryDetected = false;

    for (;;) {
 // 1.获取一个　Message; 这个需要分多种情况了. 同步消息和异步消息的　next()
        Message msg = queue.next(); // might block
        if (msg == null) {
            // No message indicates that the message queue is quitting.
            return;
        }

        // This must be in a local variable, in case a UI event sets the logger
        final Printer logging = me.mLogging;
        if (logging != null) {
            logging.println(&quot;&gt;&gt;&gt;&gt;&gt; Dispatching to &quot; + msg.target + &quot; &quot; +
                    msg.callback + &quot;: &quot; + msg.what);
        }

        final long traceTag = me.mTraceTag;
        // mSlowDispatchThresholdMs 如果 looper 的派发时长所花费的时间超过这个值的话, 就会显示警告 log
        // 这个时间长默认是 0, 当设置 thresholdOverride值的时候
        long slowDispatchThresholdMs = me.mSlowDispatchThresholdMs;
        long slowDeliveryThresholdMs = me.mSlowDeliveryThresholdMs;
        if (thresholdOverride &gt; 0) {
            slowDispatchThresholdMs = thresholdOverride;
            slowDeliveryThresholdMs = thresholdOverride;
        }
        final boolean logSlowDelivery = (slowDeliveryThresholdMs &gt; 0) &amp;&amp; (msg.when &gt; 0);
        final boolean logSlowDispatch = (slowDispatchThresholdMs &gt; 0);

        final boolean needStartTime = logSlowDelivery || logSlowDispatch;
        final boolean needEndTime = logSlowDispatch;

        if (traceTag != 0 &amp;&amp; Trace.isTagEnabled(traceTag)) {
            Trace.traceBegin(traceTag, msg.target.getTraceName(msg));
        }
// 2. 派发消息; 同时还要计算一下派发的时间
		// Looper 派发的开始时间
        final long dispatchStart = needStartTime ? SystemClock.uptimeMillis() : 0;
        // Looper 派发的结束时间
        final long dispatchEnd;
        try {
            // 调用　Handler 类的方法　dispatchMessage
            msg.target.dispatchMessage(msg);
            dispatchEnd = needEndTime ? SystemClock.uptimeMillis() : 0;
        } finally {
            if (traceTag != 0) {
                Trace.traceEnd(traceTag);
            }
        }
        // logSlowDelivery 如果设置的话, 这个值为 true, 将会显示 looper slow 的 log
        
        if (logSlowDelivery) {
            if (slowDeliveryDetected) {
                if ((dispatchStart - msg.when) &lt;= 10) {
                    Slog.w(TAG, &quot;Drained&quot;);
                    slowDeliveryDetected = false;
                }
            } else {
                if (showSlowLog(slowDeliveryThresholdMs, msg.when, dispatchStart, &quot;delivery&quot;,
                        msg)) {
                    // Once we write a slow delivery log, suppress until the queue drains.
                    slowDeliveryDetected = true;
                }
            }
        }
        if (logSlowDispatch) {
            showSlowLog(slowDispatchThresholdMs, dispatchStart, dispatchEnd, &quot;dispatch&quot;, msg);
        }

        if (logging != null) {
            logging.println(&quot;&lt;&lt;&lt;&lt;&lt; Finished to &quot; + msg.target + &quot; &quot; + msg.callback);
        }

        // Make sure that during the course of dispatching the
        // identity of the thread wasn't corrupted.
        final long newIdent = Binder.clearCallingIdentity();
        if (ident != newIdent) {
            Log.wtf(TAG, &quot;Thread identity changed from 0x&quot;
                    + Long.toHexString(ident) + &quot; to 0x&quot;
                    + Long.toHexString(newIdent) + &quot; while dispatching to &quot;
                    + msg.target.getClass().getName() + &quot; &quot;
                    + msg.callback + &quot; what=&quot; + msg.what);
        }
//3. 回收一个 Message
        msg.recycleUnchecked();
    }
}
</code></pre>
<h4 id="message-next">Message-&gt;next</h4>
<pre><code class="language-java">Message next() {
    // Return here if the message loop has already quit and been disposed.
    // This can happen if the application tries to restart a looper after quit
    // which is not supported.
    final long ptr = mPtr;
    if (ptr == 0) {
        return null;
    }

    int pendingIdleHandlerCount = -1; // -1 only during first iteration
    int nextPollTimeoutMillis = 0;
    for (;;) {
        if (nextPollTimeoutMillis != 0) {
            Binder.flushPendingCommands();
        }

        nativePollOnce(ptr, nextPollTimeoutMillis);

        synchronized (this) {
            // Try to retrieve the next message.  Return if found.
            final long now = SystemClock.uptimeMillis();
            Message prevMsg = null;
            Message msg = mMessages;
            if (msg != null &amp;&amp; msg.target == null) {
                // Stalled by a barrier.  Find the next asynchronous message in the queue.
                // 同步屏障？　do while 循环获取下一个异步消息
                do {
                    prevMsg = msg;
                    msg = msg.next;
                } while (msg != null &amp;&amp; !msg.isAsynchronous());
            }
            if (msg != null) {
                if (now &lt; msg.when) {
                    // Next message is not ready.  Set a timeout to wake up when it is ready.
                    nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE);
                } else {
                    // Got a message.
                    mBlocked = false;
                    if (prevMsg != null) {
                        prevMsg.next = msg.next;
                    } else {
                        mMessages = msg.next;
                    }
                    msg.next = null;
                    if (DEBUG) Log.v(TAG, &quot;Returning message: &quot; + msg);
                    msg.markInUse();
                    return msg;
                }
            } else {
                // No more messages.
                nextPollTimeoutMillis = -1;
            }

            // Process the quit message now that all pending messages have been handled.
            if (mQuitting) {
                dispose();
                return null;
            }

            // If first time idle, then get the number of idlers to run.
            // Idle handles only run if the queue is empty or if the first message
            // in the queue (possibly a barrier) is due to be handled in the future.
            if (pendingIdleHandlerCount &lt; 0
                    &amp;&amp; (mMessages == null || now &lt; mMessages.when)) {
                pendingIdleHandlerCount = mIdleHandlers.size();
            }
            if (pendingIdleHandlerCount &lt;= 0) {
                // No idle handlers to run.  Loop and wait some more.
                mBlocked = true;
                continue;
            }

            if (mPendingIdleHandlers == null) {
                mPendingIdleHandlers = new IdleHandler[Math.max(pendingIdleHandlerCount, 4)];
            }
            mPendingIdleHandlers = mIdleHandlers.toArray(mPendingIdleHandlers);
        }

        // Run the idle handlers.
        // We only ever reach this code block during the first iteration.
        for (int i = 0; i &lt; pendingIdleHandlerCount; i++) {
            final IdleHandler idler = mPendingIdleHandlers[i];
            mPendingIdleHandlers[i] = null; // release the reference to the handler

            boolean keep = false;
            try {
                keep = idler.queueIdle();
            } catch (Throwable t) {
                Log.wtf(TAG, &quot;IdleHandler threw exception&quot;, t);
            }

            if (!keep) {
                synchronized (this) {
                    mIdleHandlers.remove(idler);
                }
            }
        }

        // Reset the idle handler count to 0 so we do not run them again.
        pendingIdleHandlerCount = 0;

        // While calling an idle handler, a new message could have been delivered
        // so go back and look again for a pending message without waiting.
        nextPollTimeoutMillis = 0;
    }
}

</code></pre>
<h4 id="recycleunchecked">recycleUnchecked</h4>
<pre><code class="language-java">void recycleUnchecked() {
    // Mark the message as in use while it remains in the recycled object pool.
    // Clear out all other details.
    flags = FLAG_IN_USE;
    what = 0;
    arg1 = 0;
    arg2 = 0;
    obj = null;
    replyTo = null;
    sendingUid = -1;
    when = 0;
    target = null;
    callback = null;
    data = null;

    synchronized (sPoolSync) {
        if (sPoolSize &lt; MAX_POOL_SIZE) {
            next = sPool;
            sPool = this;
            sPoolSize++;
        }
    }
}

</code></pre>
<h4 id="nativemessagequeue-pollonce">NativeMessageQueue-&gt;pollOnce</h4>
<pre><code class="language-cpp">void NativeMessageQueue::pollOnce(JNIEnv* env, jobject pollObj, int timeoutMillis) {
    mPollEnv = env;
    mPollObj = pollObj;
    mLooper-&gt;pollOnce(timeoutMillis);
    mPollObj = NULL;
    mPollEnv = NULL;

    if (mExceptionObj) {
        env-&gt;Throw(mExceptionObj);
        env-&gt;DeleteLocalRef(mExceptionObj);
        mExceptionObj = NULL;
    }
}
</code></pre>
<h4 id="looper-pollonce">Looper-&gt;pollOnce</h4>
<pre><code class="language-cpp">int Looper::pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) {
    int result = 0;
    for (;;) {
        while (mResponseIndex &lt; mResponses.size()) {
            const Response&amp; response = mResponses.itemAt(mResponseIndex++);
            int ident = response.request.ident;
            if (ident &gt;= 0) {
                int fd = response.request.fd;
                int events = response.events;
                void* data = response.request.data;
#if DEBUG_POLL_AND_WAKE
                ALOGD(&quot;%p ~ pollOnce - returning signalled identifier %d: &quot;
                        &quot;fd=%d, events=0x%x, data=%p&quot;,
                        this, ident, fd, events, data);
#endif
                if (outFd != NULL) *outFd = fd;
                if (outEvents != NULL) *outEvents = events;
                if (outData != NULL) *outData = data;
                return ident;
            }
        }

        if (result != 0) {
#if DEBUG_POLL_AND_WAKE
            ALOGD(&quot;%p ~ pollOnce - returning result %d&quot;, this, result);
#endif
            if (outFd != NULL) *outFd = 0;
            if (outEvents != NULL) *outEvents = 0;
            if (outData != NULL) *outData = NULL;
            return result;
        }

        result = pollInner(timeoutMillis);
    }
}
</code></pre>
<h4 id="looper-pollinner">Looper-&gt;pollInner</h4>
<pre><code class="language-cpp">int Looper::pollInner(int timeoutMillis) {
#if DEBUG_POLL_AND_WAKE
    ALOGD(&quot;%p ~ pollOnce - waiting: timeoutMillis=%d&quot;, this, timeoutMillis);
#endif

    // Adjust the timeout based on when the next message is due.
    if (timeoutMillis != 0 &amp;&amp; mNextMessageUptime != LLONG_MAX) {
        nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC);
        int messageTimeoutMillis = toMillisecondTimeoutDelay(now, mNextMessageUptime);
        if (messageTimeoutMillis &gt;= 0
                &amp;&amp; (timeoutMillis &lt; 0 || messageTimeoutMillis &lt; timeoutMillis)) {
            timeoutMillis = messageTimeoutMillis;
        }
#if DEBUG_POLL_AND_WAKE
        ALOGD(&quot;%p ~ pollOnce - next message in %&quot; PRId64 &quot;ns, adjusted timeout: timeoutMillis=%d&quot;,
                this, mNextMessageUptime - now, timeoutMillis);
#endif
    }
    // Poll.

    int result = POLL_WAKE;
    mResponses.clear();
    mResponseIndex = 0;

    // We are about to idle.
    mPolling = true;

    struct epoll_event eventItems[EPOLL_MAX_EVENTS];
    int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_EVENTS, timeoutMillis);

    // No longer idling.
    mPolling = false;

    // Acquire lock.
    mLock.lock();

    // Rebuild epoll set if needed.
    if (mEpollRebuildRequired) {
        mEpollRebuildRequired = false;
        rebuildEpollLocked();
        goto Done;
    }

    // Check for poll error.
    if (eventCount &lt; 0) {
        if (errno == EINTR) {
            goto Done;
        }
        ALOGW(&quot;Poll failed with an unexpected error: %s&quot;, strerror(errno));
        result = POLL_ERROR;
        goto Done;
    }

    // Check for poll timeout.
    if (eventCount == 0) {
#if DEBUG_POLL_AND_WAKE
        ALOGD(&quot;%p ~ pollOnce - timeout&quot;, this);
#endif
        result = POLL_TIMEOUT;
        goto Done;
    }

    // Handle all events.
#if DEBUG_POLL_AND_WAKE
    ALOGD(&quot;%p ~ pollOnce - handling events from %d fds&quot;, this, eventCount);
#endif

    for (int i = 0; i &lt; eventCount; i++) {
        int fd = eventItems[i].data.fd;
        uint32_t epollEvents = eventItems[i].events;
        if (fd == mWakeEventFd) {
            if (epollEvents &amp; EPOLLIN) {
                awoken();
            } else {
                ALOGW(&quot;Ignoring unexpected epoll events 0x%x on wake event fd.&quot;, epollEvents);
            }
        } else {
            ssize_t requestIndex = mRequests.indexOfKey(fd);
            if (requestIndex &gt;= 0) {
                int events = 0;
                if (epollEvents &amp; EPOLLIN) events |= EVENT_INPUT;
                if (epollEvents &amp; EPOLLOUT) events |= EVENT_OUTPUT;
                if (epollEvents &amp; EPOLLERR) events |= EVENT_ERROR;
                if (epollEvents &amp; EPOLLHUP) events |= EVENT_HANGUP;
                pushResponse(events, mRequests.valueAt(requestIndex));
            } else {
                ALOGW(&quot;Ignoring unexpected epoll events 0x%x on fd %d that is &quot;
                        &quot;no longer registered.&quot;, epollEvents, fd);
            }
        }
    }
Done: ;

    // Invoke pending message callbacks.
    mNextMessageUptime = LLONG_MAX;
    while (mMessageEnvelopes.size() != 0) {
        nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC);
        const MessageEnvelope&amp; messageEnvelope = mMessageEnvelopes.itemAt(0);
        if (messageEnvelope.uptime &lt;= now) {
            // Remove the envelope from the list.
            // We keep a strong reference to the handler until the call to handleMessage
            // finishes.  Then we drop it so that the handler can be deleted *before*
            // we reacquire our lock.
            { // obtain handler
                sp&lt;MessageHandler&gt; handler = messageEnvelope.handler;
                Message message = messageEnvelope.message;
                mMessageEnvelopes.removeAt(0);
                mSendingMessage = true;
                mLock.unlock();

#if DEBUG_POLL_AND_WAKE || DEBUG_CALLBACKS
                ALOGD(&quot;%p ~ pollOnce - sending message: handler=%p, what=%d&quot;,
                        this, handler.get(), message.what);
#endif
                handler-&gt;handleMessage(message);
            } // release handler

            mLock.lock();
            mSendingMessage = false;
            result = POLL_CALLBACK;
        } else {
            // The last message left at the head of the queue determines the next wakeup time.
            mNextMessageUptime = messageEnvelope.uptime;
            break;
        }
    }

    // Release lock.
    mLock.unlock();

    // Invoke all response callbacks.
    for (size_t i = 0; i &lt; mResponses.size(); i++) {
        Response&amp; response = mResponses.editItemAt(i);
        if (response.request.ident == POLL_CALLBACK) {
            int fd = response.request.fd;
            int events = response.events;
            void* data = response.request.data;
#if DEBUG_POLL_AND_WAKE || DEBUG_CALLBACKS
            ALOGD(&quot;%p ~ pollOnce - invoking fd event callback %p: fd=%d, events=0x%x, data=%p&quot;,
                    this, response.request.callback.get(), fd, events, data);
#endif
            // Invoke the callback.  Note that the file descriptor may be closed by
            // the callback (and potentially even reused) before the function returns so
            // we need to be a little careful when removing the file descriptor afterwards.
            int callbackResult = response.request.callback-&gt;handleEvent(fd, events, data);
            if (callbackResult == 0) {
                removeFd(fd, response.request.seq);
            }

            // Clear the callback reference in the response structure promptly because we
            // will not clear the response vector itself until the next poll.
            response.request.callback.clear();
            result = POLL_CALLBACK;
        }
    }
    return result;
}
</code></pre>
<pre><code class="language-java">/**
    * Subclasses must implement this to receive messages.
    */
public void handleMessage(Message msg) {
    // 空实现，由子类实现这个方法
}

/**
    * Handle system messages here.
    */
// 派发消息
public void dispatchMessage(Message msg) {
    if (msg.callback != null) {
        handleCallback(msg);
    } else {
        // mCallback 是构造函数的里的 Callback, 也就是通常的 new Handler.Callback()
        if (mCallback != null) {
            // 如果返回 false, 将会继续分发给 Handler 本身的 handleMessage 方法
            if (mCallback.handleMessage(msg)) {
                return;
            }
        }
        handleMessage(msg);
    }
}
</code></pre>
<h3 id="obtainmessage-流程">obtainMessage 流程</h3>
<h3 id="分析">分析</h3>
<p>Handler 如何实现 线程间的通信<br>
Handler 作用:</p>
<ol>
<li>安排调度(scheule)消息和可执行的runnable，可以立即执行，也可以安排在某个将来的时间点执行。</li>
</ol>
<p>2.让某一个行为（action）在其他线程中执行</p>
<p>线程间的通信其他方式<br>
1. 等待通知模式是 Java 中比较经典的线程通信方式。<br>
2. volatile 共享内存<br>
3. CyclicBarrier 中文名叫做屏障或者是栅栏，也可以用于线程间通信。<br>
4. join() 也是利用的等待通知机制：<br>
5. CountDownLatch 可以实现 join 相同的功能，但是更加的灵活。<br>
6. 管道通信<br>
因为 Java 是采用共享内存的方式进行线程通信的，</p>
<h2 id="activiththread-里的-h">ActivithThread 里的 H</h2>
<h2 id="相关面试问题">相关面试问题</h2>
<h3 id="子线程中创建handler会抛异常">子线程中创建Handler会抛异常</h3>
<h3 id="谈谈-handler-机制和原理">谈谈 Handler 机制和原理</h3>
<h3 id="自定义-handler-时如何有效地避免内存泄漏问题">自定义 Handler 时如何有效地避免内存泄漏问题</h3>
<p>一般非静态内部类持有外部类的引用的情况下，造成外部类在使用完成后不能被系统回收内存，从而造成内存泄漏。这里 Handler 持有外部类 Activity 的引用，一旦 Activity 被销毁，而此时 Handler 依然持有 Activity 引用，就会造成内存泄漏<br>
如果在非自定义 Handler 情况下，还可以通过 Activity 生命周期来及时清除消息，从而及时回收 Activity：<br>
是的，正如楼上所说，其实正常情况下是不会内存泄漏的，除非handler队列等待太久</p>
<ol>
<li>自定的 Handler 使用 static 修饰, 使其成为静态内部类</li>
<li>handler 使用弱引用</li>
<li>还有一个主意的就是当你activity被销毁的时候如果还有消息没有发出去 就remove掉吧</li>
<li>removecallbacksandmessages去清除Message和Runnable 加null 写在生命周的ondestroy()就行</li>
</ol>
<h3 id="同步屏障">同步屏障</h3>
<h2 id="参考文献">参考文献</h2>
<ol>
<li><a href="http://droidyue.com/blog/2015/11/08/make-use-of-handlerthread/?utm_source=tuicool&amp;utm_medium=referral">详解 Android 中的 HandlerThread</a></li>
<li><a href="http://www.jianshu.com/p/f6f357b3db89">Android源码解析Handler系列第（一）篇 --- Message全局池</a></li>
<li><a href="http://www.jianshu.com/p/411c40b09a81">Android源码解析Handler系列第（二）篇--- ThreadLocal详解</a></li>
<li><a href="http://www.jianshu.com/p/325d3cd79fd5">Android源码解析Handler系列第（三）篇---深入了解Android的消息机制</a></li>
<li><a href="http://www.jianshu.com/p/338cce832cc9">Android源码解析Handler系列第（四）篇 --- 打破Handler那些困惑事儿</a></li>
<li><a href="http://www.jianshu.com/p/35c8567419fa">Android源码解析Handler系列第（五）篇 ---HandlerThread你用过吗？</a></li>
<li><a href="http://www.jianshu.com/p/b03d46809c4d">一步一步分析Android的Handler机制</a></li>
<li><a href="https://crossoverjie.top/2018/03/16/java-senior/thread-communication/">深入理解线程通信 </a></li>
<li><a href="https://github.com/Moosphan/Android-Daily-Interview/issues/1">自定义 Handler 时如何有效地避免内存泄漏问题？</a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
</ol>

            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="http://xuwanjin.me//post/add_new_partition_on_mtk_9.0_platform">
              <h3 class="post-title">
                MTK 9.0 平台添加一个分区
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="http://xuwanjin.me//atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

      </div>
    </div>
  </body>
</html>
